{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4 # length of my input sentence - \"My name is Vibhav\"\n",
    "batch_size = 1 # Batch size is going to help in parallel processing, in this case i am setting it to be 1 for illustrative purposes \n",
    "input_dim = 512 # Vector dimension of every word that goes into the Attention Unit (512x1)\n",
    "d_model = 512 # Output of the Attention Unit for Every Single Word\n",
    "x = torch.randn((batch_size,sequence_length,input_dim)) # Some randomly Sample Input since i am not going to create the position encoding and the input face right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The x value is not the one that exists before feeding to the input Embedding\n",
    "# It is the one that exists after passing through the postional encoding and ready to enter into the Multiheaded Attention\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to input_dim from 512 to 3 * d_model because of the q,k,v vectors, All Concatenated all of them have the 8 Attention heads\n",
    "# We will split them up later\n",
    "qkv_layer = nn.Linear(input_dim,3*d_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 batch we have 4 words each one of size 1536 (512 x 3) - 3 because of each vector will have Q,K and V\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv,bins=200,min=-3,max=3)\n",
    "x_val = np.arange(-1,1,0.01) * 3\n",
    "plt.bar(x_val,y_val,align='center',color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 8 Attention heads \n",
    "num_heads = 8\n",
    "# Each of them will be 512/8 - which will be 64\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size,sequence_length,num_heads,3 * head_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv = qkv.permute(0,2,1,3) # (batch_size,num_heads,sequence_length,3*head_dim)\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q,k,v = qkv.chunk(3,dim=-1)\n",
    "q.shape,k.shape,v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention for Multiple Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q,k.transpose(-2,-1))/math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0607, -1.4086, -0.8819],\n",
       "        [ 1.0135,  0.0851,  0.5692]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(2,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0607,  1.0135],\n",
       "        [-1.4086,  0.0851],\n",
       "        [-0.8819,  0.5692]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0th row will become as the 1th column \n",
    "# 1st row will become the 2st column\n",
    "torch.transpose(y,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0607,  1.0135],\n",
       "        [-1.4086,  0.0851],\n",
       "        [-0.8819,  0.5692]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We Require masking in decoding face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.full(scaled.size(), float('-inf'))\n",
    "mask = torch.triu(mask,diagonal=1)\n",
    "mask[0][1] # maks for input to a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1624,    -inf,    -inf,    -inf],\n",
       "        [-0.3959,  0.4031,    -inf,    -inf],\n",
       "        [ 0.2607, -0.1811,  0.5453,    -inf],\n",
       "        [-0.2770,  0.0468, -0.3119, -0.2425]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0] # This is the tensor for one head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31023946919618034"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.3959) / (np.exp(-0.3959) + np.exp(0.4031))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3102, 0.6898, 0.0000, 0.0000],\n",
       "        [0.3365, 0.2163, 0.4472, 0.0000],\n",
       "        [0.2281, 0.3154, 0.2203, 0.2362]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention,v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def scaled_dot_product(q,k,v,mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q,k.transpose(-1,-2))/math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled,dim=-1)\n",
    "    values = torch.matmul(attention,v)\n",
    "    return values,attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,attention = scaled_dot_product(q,k,v,mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3102, 0.6898, 0.0000, 0.0000],\n",
       "        [0.3365, 0.2163, 0.4472, 0.0000],\n",
       "        [0.2281, 0.3154, 0.2203, 0.2362]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we pass the mask which we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,attention = scaled_dot_product(q,k,v,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3102, 0.6898, 0.0000, 0.0000],\n",
       "        [0.3365, 0.2163, 0.4472, 0.0000],\n",
       "        [0.2281, 0.3154, 0.2203, 0.2362]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = values.reshape(batch_size,sequence_length,num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1390,  0.1109,  0.1932,  ...,  0.2363, -0.1836, -0.0667],\n",
       "         [ 0.5077,  0.1802,  0.1014,  ..., -0.3387, -0.3823,  0.6150],\n",
       "         [ 0.4399, -0.1081,  0.2979,  ..., -0.0502,  0.0353,  0.2105],\n",
       "         [-0.3011,  0.1313, -0.1064,  ..., -0.0871,  0.2267,  0.0884]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Combined as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
